{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP4-ExequielSantucho-DATITOS","provenance":[{"file_id":"1PvynNB8MxchaeetV6EDmh0oiBEenrNbu","timestamp":1619452557415}],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"afcc86fd1165446bb1eb968c078d3786":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c76da15fa3df42c1a02cd6dae0a4a6fa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f9130851ae4644e1811023cb995265b1","IPY_MODEL_8b43533d9ab6455f8bc86a22c28b54c6"]}},"c76da15fa3df42c1a02cd6dae0a4a6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9130851ae4644e1811023cb995265b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e8f434a64abe4db5807e2d3fa791da64","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6467e20e6d054759a23d0e80fe2e0ce3"}},"8b43533d9ab6455f8bc86a22c28b54c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8af56d6b520468dbe8088aa145e38f2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:26&lt;00:00, 6513246.37it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b679343b618846aba16ec9570474bc36"}},"e8f434a64abe4db5807e2d3fa791da64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6467e20e6d054759a23d0e80fe2e0ce3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8af56d6b520468dbe8088aa145e38f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b679343b618846aba16ec9570474bc36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"xsQDziRvK1Ti","executionInfo":{"status":"ok","timestamp":1619636121165,"user_tz":180,"elapsed":2437,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["#@title Aprendizaje Profundo | Otoño 2021 by Datitos{display-mode: \"form\" }\n","#@markdown ![71335171.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAACwElEQVR4nOzdMY7iQBBA0WU197/FnJNNJ/FqWvLHZfd7McIGfVVQos3X+/3+A2f7e/UN8EzCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBJfV9/A/7xer6XX3/1/gZ70eU0sEsIiISwSwiIhLBLCIiEsEiP2WEf7m9U9zVnvU9vh85pYJIRFQlgkhEVCWCSERUJYJEbssc5ytL+5at8zec9UM7FICIuEsEgIi4SwSAiLhLBIPGqPdWR1v1VfdwcmFglhkRAWCWGREBYJYZEQFokt9lhHdt4z1UwsEsIiISwSwiIhLBLCIiEsEh/dY+18zq4w7RzlTyYWCWGREBYJYZEQFglhkRAWiS1+jzVhr/Mbd7nP3zCxSAiLhLBICIuEsEgIi4SwSDxqj1U/72r1ulc9l2sCE4uEsEgIi4SwSAiLhLBICIvE7D3W9/fSy6/63dLqdZfvc/F7mMDEIiEsEsIiISwSwiIhLBLCIjF7j3WSs87rTXufyUwsEsIiISwSwiIhLBLCIiEsEq8Ju5N6r3OXc3xP2oeZWCSERUJYJIRFQlgkhEVCWCRG7LGOTN7TfNIdvwcTi4SwSAiLhLBICIuEsEgIi8Toc4U7Pyf9p8n7qiMmFglhkRAWCWGREBYJYZEQFonRe6wjd9zr7MbEIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIi8S8AAP//HtRtH09JwIEAAAAASUVORK5CYII=)\n","#El siguiente notebook fue traducido por Pablo Marinozi como el cuarto trabajo práctico correspondiente a la versión de Otoño del 2021 del curso Aprendizaje Profundo organizado por Datitos\n","#El trabajo original fue diseñado por los docentes de la CS231n: Convolutional Neural Networks for Visual Recognition de la Universidad de Stanford. http://cs231n.stanford.edu\n","#Para mayor información consultar https://datitos.github.io/curso-aprendizaje-profundo/#calendario"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y5gmNsPl3N2b"},"source":["# Trabajo Práctico N°4: Redes Neuronales Convolucionales"]},{"cell_type":"markdown","metadata":{"id":"TkXbLl91whfS"},"source":["# Tabla de contenido\n","\n","Esta tarea tiene 4 partes. Vas a aprender PyTorch en **dos niveles diferentes de abstracción**, lo que te ayudará a comprenderlo mejor y a prepararte para el proyecto final.\n","\n","1. **Parte I**: Preparación: utilizaremos el conjunto de datos CIFAR-10.\n","2. **Parte II**: API de Module de PyTorch: **Nivel de abstracción 1**, usaremos `nn.Module` para definir la arquitectura arbitraria de una red neuronal .\n","3. **Parte III**: API de Sequential de PyTorch: **Nivel de abstracción 2**, usaremos `nn.Sequential` para definir muy convenientemente una red de avance en serie .\n","4. **Parte IV**: Desafío abierto de CIFAR-10: implemente su propia red para obtener la mayor precisión posible en CIFAR-10. Puede experimentar con cualquier capa, optimizador, hiperparámetros u otras funciones avanzadas.\n","\n","Aquí hay una tabla de comparación:\n","\n","| API | Flexibilidad | Conveniencia |\n","| --------------- | ------------- | ------------- |\n","| `nn.Module` | Alta | Media |\n","| `nn.Sequential` | Baja | Alta | "]},{"cell_type":"markdown","metadata":{"id":"9K3WcmlbwhfU"},"source":["# Parte I.Preparación\n","\n","Primero, cargamos el conjunto de datos CIFAR-10. Esto puede tardar un par de minutos la primera vez que lo hagás, pero los archivos deberían permanecer almacenados en caché después de eso.\n","\n","PyTorch proporciona herramientas convenientes para automatizar el proceso de preprocesarlo e iterarlo en minibatches."]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"id":"F4h9tKaEwhfX","executionInfo":{"status":"ok","timestamp":1619636126112,"user_tz":180,"elapsed":7376,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F  # useful stateless functions\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torch.utils.data import sampler\n","\n","import torchvision.datasets as dset\n","import torchvision.transforms as T\n","\n","import numpy as np"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"cfClpLJu8WJ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619636140722,"user_tz":180,"elapsed":21980,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"98e58aec-3eb5-45c3-e88b-330005a9c413"},"source":["  !wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -O cifar-10-python.tar.gz\n","  !tar -xzvf cifar-10-python.tar.gz\n","  !rm cifar-10-python.tar.gz"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2021-04-28 18:55:23--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  16.0MB/s    in 11s     \n","\n","2021-04-28 18:55:35 (14.2 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n","cifar-10-batches-py/\n","cifar-10-batches-py/data_batch_4\n","cifar-10-batches-py/readme.html\n","cifar-10-batches-py/test_batch\n","cifar-10-batches-py/data_batch_3\n","cifar-10-batches-py/batches.meta\n","cifar-10-batches-py/data_batch_2\n","cifar-10-batches-py/data_batch_5\n","cifar-10-batches-py/data_batch_1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"tags":["pdf-ignore"],"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["afcc86fd1165446bb1eb968c078d3786","c76da15fa3df42c1a02cd6dae0a4a6fa","f9130851ae4644e1811023cb995265b1","8b43533d9ab6455f8bc86a22c28b54c6","e8f434a64abe4db5807e2d3fa791da64","6467e20e6d054759a23d0e80fe2e0ce3","f8af56d6b520468dbe8088aa145e38f2","b679343b618846aba16ec9570474bc36"]},"id":"AS7t7M8CwhfY","executionInfo":{"status":"ok","timestamp":1619636157113,"user_tz":180,"elapsed":38364,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"d5ffdab5-154a-4e51-f31f-bcde6776d8bb"},"source":["NUM_TRAIN = 49000\n","\n","# El paquete torchvision.transforms proporciona herramientas para preprocesar datos\n","# y para realizar el aumento de datos; aquí configuramos una variable transform para\n","# normalizar los datos restando el valor RGB medio y dividiendo por el\n","# desviación estándar de cada valor RGB; hemos \"hardcodeado\" la media y la desviación estándar.\n","transform = T.Compose([\n","                T.ToTensor(),\n","                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","            ])\n","\n","# Configuramos un objeto Dataset para cada split (train / val / test); torchvision.datasets carga\n","# ejemplos de entrenamiento uno a la vez, por lo que empaquetamos cada conjunto de datos en un DataLoader que\n","# itera a través del conjunto de datos y forma minibatches. Dividimos el conjunto de entrenamiento de CIFAR-10\n","# en los conjuntos train y val pasando un objeto Sampler al DataLoader indicando cómo debe muestrear el conjunto de datos subyacente.\n","cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n","                             transform=transform)\n","loader_train = DataLoader(cifar10_train, batch_size=64, \n","                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n","\n","cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n","                           transform=transform)\n","loader_val = DataLoader(cifar10_val, batch_size=64, \n","                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n","\n","cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n","                            transform=transform)\n","loader_test = DataLoader(cifar10_test, batch_size=64)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cs231n/datasets/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afcc86fd1165446bb1eb968c078d3786","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./cs231n/datasets/cifar-10-python.tar.gz to ./cs231n/datasets\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"tags":["pdf-ignore"],"id":"tUZo6WPKwhfZ"},"source":["Tenés la opción de **usar GPU configurando la variable `USE_GPU` en True en la celda de abajo**. No es estrictamente necesario utilizar GPU para este práctico, aunque habilitarla ocasionará que el entrenamiento demore menos. Tené en cuenta que si tu computadora no tiene CUDA habilitado, `torch.cuda.is_available ()` devolverá False y este notebook regresará al modo CPU.\n","\n","Las variables globales `dtype` y` device` controlarán los tipos de datos a lo largo de este práctico.\n","\n","## Usuarios de Colab\n","\n","Si estás utilizando Colab, tenés que cambiar manualmente a un dispositivo GPU. Podés hacer esto haciendo clic en `Entorno de ejecución -> Cambiar tipo de entorno de ejecución` y seleccionando` GPU` en `Acelerador de hardware`. Tené en cuenta que tenés que volver a ejecutar las celdas desde arriba, porque el kernel se reinicia al cambiar los entornos de ejecución."]},{"cell_type":"code","metadata":{"tags":["pdf-ignore-input"],"colab":{"base_uri":"https://localhost:8080/"},"id":"W_P5xHYSwhfb","executionInfo":{"status":"ok","timestamp":1619636157114,"user_tz":180,"elapsed":38358,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"cda69000-e9fc-4c87-b22f-9af5e2c94a9e"},"source":["USE_GPU = True\n","\n","dtype = torch.float32 # vamos a usar float a lo largo de este tutorial\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","# Constante para controlar la frecuencia con la que imprimimos la pérdida durante el entrenamiento\n","print_every = 100\n","\n","print('using device:', device)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["using device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WWejmW9mwhfx"},"source":["# Parte III. API Module de PyTorch\n","\n","PyTorch proporciona la API `nn.Module` para que definas arquitecturas de red arbitrarias, mientras realizás un seguimiento de todos los parámetros aprendibles. PyTorch también proporciona el paquete `torch.optim` que implementa todos los optimizadores comunes, como RMSProp, Adagrad y Adam.\n","\n","Para utilizar la API Module, siga los pasos a continuación:\n","\n","1. Genere una subclase de `nn.Module`. Dé a su clase de red un nombre intuitivo como \"2CapasMLP\".\n","\n","2. En el constructor `__init __ ()`, defina todas las capas que necesita como atributos de clase. Los objetos de capa como `nn.Linear` y` nn.Conv2d` son en sí mismos subclases de `nn.Module` y contienen parámetros que se pueden aprender, por lo que no tenés que crear una instancia para esos tensores. `nn.Module` monitoreará estos parámetros internos por vos. Consultá la [documentación] (http://pytorch.org/docs/master/nn.html) para obtener más información sobre las docenas de capas integradas en Pytorch. ** Advertencia **: ¡no te olvidés dellamar al `super () .__ init __ ()` primero!**\n","\n","3. En el método `forward()`, definí la *conectividad* de tu red. Tenés usar los atributos definidos en `__init__` como llamadas de función que toman el tensor como entrada y generan como salida al tensor \"transformado\". **No** creés capas nuevas con parámetros que se puedan aprender en `forward()`! Todos ellos tienen que declararse por adelantado en `__init__`.\n","\n","Después de definir la subclase de Module, podés instanciarla como un objeto y llamarla como una función.\n","\n","### API Module: MLP de dos capas\n","A continuación, se muestra un ejemplo concreto de un MLP de dos capas"]},{"cell_type":"code","metadata":{"tags":["pdf-ignore-input"],"id":"NAGJ6z-_3QNP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619636157114,"user_tz":180,"elapsed":38351,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"2c41fa1f-50c7-4681-d418-eef1ee226d5c"},"source":["def flatten(x):\n","    N = x.shape[0] # lee un tensor con dimensiones N, C, H, W\n","    return x.view(N, -1)  # \"aplana\" las componentes C * H * W ven un solo vector por imagen\n","\n","def test_flatten():\n","    x = torch.arange(12).view(2, 1, 3, 2)\n","    print('Antes de flatten: ', x,'\\n')\n","    print('Después de flatten: ', flatten(x))\n","\n","test_flatten()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Antes de flatten:  tensor([[[[ 0,  1],\n","          [ 2,  3],\n","          [ 4,  5]]],\n","\n","\n","        [[[ 6,  7],\n","          [ 8,  9],\n","          [10, 11]]]]) \n","\n","Después de flatten:  tensor([[ 0,  1,  2,  3,  4,  5],\n","        [ 6,  7,  8,  9, 10, 11]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXfmAtVwwhfx","executionInfo":{"status":"ok","timestamp":1619636157115,"user_tz":180,"elapsed":38345,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"000054e4-bff5-4955-bfb0-d7194f527c83"},"source":["class DosCapasMLP(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super().__init__()\n","        # asigna instancias de capas a los atributos de la clase\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        # nn.init contiene métodos de inicialización convenientes\n","        # http://pytorch.org/docs/master/nn.html#torch-nn-init \n","        nn.init.kaiming_normal_(self.fc1.weight)\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","        nn.init.kaiming_normal_(self.fc2.weight)\n","    \n","    def forward(self, x):\n","        # forward siempre define la conectividad\n","        x = flatten(x)\n","        scores = self.fc2(F.relu(self.fc1(x)))\n","        return scores\n","\n","def test_DosCapasMLP():\n","    input_size = 50\n","    x = torch.zeros((64, input_size), dtype=dtype)  # minibatch size 64, feature dimension 50\n","    model = DosCapasMLP(input_size, 42, 10)\n","    scores = model(x)\n","    print(scores.size())  # deberías ver [64, 10]\n","\n","test_DosCapasMLP()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["torch.Size([64, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lkbpEu-Rwhfy"},"source":["###API Module: CNN de 3 Capas\n","Es tu turno de implementar una CNN de 3 capas seguida de una capa densa. La arquitectura de la red debe ser la siguiente:\n","\n","1. Capa convolucional con una cantidad `channel_1` de filtros de 5x5 con padding=2\n","2. ReLU\n","3. Capa convolucional con una cantidad `channel_2` de filtros 3x3 con padding=1\n","4. ReLU\n","5. Capa densa con una cantidad `num_classes` de neuronas de salida.\n","\n","Tenés que inicializar las matrices de peso del modelo utilizando el método de inicialización normal de Kaiming.\n","\n","**PISTA**: http://pytorch.org/docs/stable/nn.html#conv2d\n","\n","Después de implementar la CNN de tres capas, la función `test_TresCapasCNN` ejecutará su implementación; debería imprimir `(64, 10)`."]},{"cell_type":"code","metadata":{"id":"module_output_shape","executionInfo":{"status":"ok","timestamp":1619636572640,"user_tz":180,"elapsed":1176,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["class TresCapasCNN(nn.Module):\n","    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n","        super().__init__()\n","        ########################################################################\n","        # TO_DO: Configure las capas que necesita para la CNN de tres capas con#\n","        # la arquitectura definida anteriormente.                              #\n","        ########################################################################\n","        # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) ***** \n","\n","        # Argumentos función CNN: torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n","        # Formula: cálculo salida capas convolucionales: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d o \"Hardcodear\"\n","        # Ejemplo implementación CNN: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n","        # Capa convolucional 1:\n","        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, padding=2)\n","        nn.init.kaiming_normal_(self.conv1.weight)\n","        # Capa convolucional 2:\n","        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1)\n","        nn.init.kaiming_normal_(self.conv2.weight)\n","        # Capa densa:\n","        self.fc1 = nn.Linear(16*32*32, num_classes) # Hardcodeado el input (luego de correr y que tire error. La dimensión de la capa anterior es \"torch.Size([64, 8, 32, 32])\")\n","        nn.init.kaiming_normal_(self.fc1.weight)\n","        # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n","        ########################################################################\n","        #                          FINAL DE TU CÓDIGO                          #       \n","        ########################################################################\n","\n","        ########################################################################\n","        # TODO: Implementá la función forward para la CNN de 3 capas. Deberías #\n","        # usar las capas que definiste en __init__ y especificar la            #\n","        # conectividad de dichas capas                                         #\n","        ########################################################################\n","        # ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n","        \n","    def forward(self, x):\n","        #print(x.shape) # Activar/desactivar para Hardcodear la definición de capas\n","        x = F.relu(self.conv1(x))\n","        #print(x.shape) # Activar/desactivar para Hardcodear la definición de capas\n","        x = F.relu(self.conv2(x))\n","        #print(x.shape) # Activar/desactivar para Hardcodear la definición de capas\n","        x = flatten(x)\n","        #print(x.shape)\n","        scores = self.fc1(x)\n","        return scores\n","\n","        # ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n","        ########################################################################\n","        #                          FINAL DE TU CÓDIGO                          #       \n","        ########################################################################\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t8VpC9bJ2vZ9","executionInfo":{"status":"ok","timestamp":1619636565363,"user_tz":180,"elapsed":1248,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"e5406565-fe82-4031-dc37-56235cda2f96"},"source":["def test_TresCapasCNN():\n","    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n","    model = TresCapasCNN(in_channel=3, channel_1=12, channel_2=8, num_classes=10) # Harcodear TresCapasCNN: cambiar entrada de capa densa a: 8*32*32\n","    #print(model)\n","    scores = model(x)\n","    print(scores.size())  # deberías ver [64, 10]\n","\n","test_TresCapasCNN()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["torch.Size([64, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_0FJhB65whf0"},"source":["### Module API: Calcular Accuracy\n","Dado el conjunto de pruebas o de validación, podemos verificar el accuracy de clasificación de una red neuronal.\n"]},{"cell_type":"code","metadata":{"id":"riYGuGXHwhf1","executionInfo":{"status":"ok","timestamp":1619636157115,"user_tz":180,"elapsed":38332,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["def check_accuracy_part34(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on validation set')\n","    else:\n","        print('Checking accuracy on test set')   \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()  # set model to evaluation mode\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AbncEWl6whf1"},"source":["### Module API: Bucle de entrenamiento\n","En lugar de actualizar los valores de los pesos nosotros mismos, utilizamos un objeto Optimizer del paquete `torch.optim`, que abstrae la noción de un algoritmo de optimización y proporciona implementaciones de la mayoría de los algoritmos comúnmente utilizados para esta tarea."]},{"cell_type":"code","metadata":{"id":"3Jv-hTALwhf3","executionInfo":{"status":"ok","timestamp":1619638528473,"user_tz":180,"elapsed":810,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["def train_part34(model, optimizer, epochs=1):\n","    \"\"\"\n","    Entrena un modelo en CIFAR-10 usando la API Module de PyTorch.\n","\n","    Entradas:\n","    - model: Un Module de PyTorch que da el modelo a entrenar.\n","    - optimizer: un objeto Optimizador que usaremos para entrenar el modelo\n","    - epochs: (Opcional) Un número entero de Python que da el número de épocas para entrenar\n","\n","    Devuelve: nada, pero imprime la precisión del modelo durante el entrenamiento.\n","    \"\"\" \n","    model = model.to(device=device)  # mueve los parámetros del modelo to CPU/GPU\n","    for e in range(epochs):\n","        print('Epoch %d' % (e))\n","        for t, (x, y) in enumerate(loader_train):\n","            model.train()  # pone el modelo en modo entrenamiento\n","            x = x.to(device=device, dtype=dtype)  # mover a device, e.g. GPU\n","            y = y.to(device=device, dtype=torch.long)\n","\n","            scores = model(x)\n","            loss = F.cross_entropy(scores, y)\n","\n","            # Pone a cero todos los gradientes de las variables que el optimizador\n","            # actualizará.\n","            optimizer.zero_grad()\n","\n","            # Este es el paso de propagación hacia atrás: calcula el gradiente \n","            # de la función de pérdida con respecto a cada parámetro del modelo.\n","            loss.backward()\n","\n","            # Efectivamente actualiza los parámetros del modelo usando los gradientes\n","            # calculado por el paso anterior\n","            optimizer.step()\n","\n","            if t % print_every == 0:\n","                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n","                check_accuracy_part34(loader_val, model)\n","                print()"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iLWRWRJCwhf3"},"source":["### API Module: Entrenamiento de un MLP de dos capas\n","Ahora estamos listos para ejecutar el ciclo de entrenamiento. \n","\n","Simplemente pasá el tamaño de la entrada, el tamaño de la capa oculta y el número de clases (es decir, el tamaño de salida) al constructor de `DosCapasMLP`.\n","\n","También necesitas definir un optimizador que monitoree todos los parámetros que se pueden aprender dentro de `DosCapasMLP`.\n","\n","No tenés que ajustar ningún hiperparámetro, pero deberías obtener un accuracy del modelo por encima del 40% después de una sola época de entrenamiento ."]},{"cell_type":"code","metadata":{"id":"qBDCm9PQwhf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619636176731,"user_tz":180,"elapsed":57938,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"df11669f-c16a-4803-9f01-d923f3d1c39c"},"source":["hidden_layer_size = 4000\n","learning_rate = 1e-2\n","model = DosCapasMLP(3 * 32 * 32, hidden_layer_size, 10)\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","\n","train_part34(model, optimizer)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 0\n","Iteration 0, loss = 3.9543\n","Checking accuracy on validation set\n","Got 147 / 1000 correct (14.70)\n","\n","Iteration 100, loss = 1.9943\n","Checking accuracy on validation set\n","Got 345 / 1000 correct (34.50)\n","\n","Iteration 200, loss = 2.4842\n","Checking accuracy on validation set\n","Got 384 / 1000 correct (38.40)\n","\n","Iteration 300, loss = 1.8504\n","Checking accuracy on validation set\n","Got 433 / 1000 correct (43.30)\n","\n","Iteration 400, loss = 1.8570\n","Checking accuracy on validation set\n","Got 428 / 1000 correct (42.80)\n","\n","Iteration 500, loss = 1.8232\n","Checking accuracy on validation set\n","Got 413 / 1000 correct (41.30)\n","\n","Iteration 600, loss = 1.6359\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n","Iteration 700, loss = 1.6633\n","Checking accuracy on validation set\n","Got 454 / 1000 correct (45.40)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rcErV7FGwhf4"},"source":["###API Module: Entrenamiento de una CNN de 3 Capas\n","Ahora deberías usar la API de Module para entrenar una CNN de tres capas en CIFAR. ¡Esto debería ser muy similar al entrenamiento de la red de dos capas! No necesitás ajustar ningún hiperparámetro, pero deberías alcanzar más del 45% después de entrenar durante una época.\n","\n","Deberías entrenar el modelo usando un descenso de gradiente estocástico sin momentum."]},{"cell_type":"code","metadata":{"id":"module_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619637595913,"user_tz":180,"elapsed":10094,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"a46646a6-d058-4e41-af11-336a83c89f1a"},"source":["learning_rate = 3e-3\n","channel_1 = 32\n","channel_2 = 16\n","\n","model = None\n","optimizer = None\n","\n","#############################################################################\n","# TODO: Creá una instancia de TresCapasCNN y un optimizador correspondiente #\n","#############################################################################\n","# ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****\n","\n","model = TresCapasCNN(in_channel=3, channel_1=channel_1, channel_2=channel_2, num_classes=10) # Harcodear TresCapasCNN: cambiar entrada de capa densa a: 16*32*32\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n","\n","# ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****       #\n","#############################################################################\n","#                          FINAL DE TU CÓDIGO                               #       \n","#############################################################################\n","\n","train_part34(model, optimizer)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch 0\n","Iteration 0, loss = 3.5740\n","Checking accuracy on validation set\n","Got 100 / 1000 correct (10.00)\n","\n","Iteration 100, loss = 2.1559\n","Checking accuracy on validation set\n","Got 324 / 1000 correct (32.40)\n","\n","Iteration 200, loss = 1.6082\n","Checking accuracy on validation set\n","Got 386 / 1000 correct (38.60)\n","\n","Iteration 300, loss = 1.6657\n","Checking accuracy on validation set\n","Got 410 / 1000 correct (41.00)\n","\n","Iteration 400, loss = 1.6283\n","Checking accuracy on validation set\n","Got 416 / 1000 correct (41.60)\n","\n","Iteration 500, loss = 1.8455\n","Checking accuracy on validation set\n","Got 460 / 1000 correct (46.00)\n","\n","Iteration 600, loss = 1.4013\n","Checking accuracy on validation set\n","Got 465 / 1000 correct (46.50)\n","\n","Iteration 700, loss = 1.6020\n","Checking accuracy on validation set\n","Got 488 / 1000 correct (48.80)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kkgdRb8cwhf5"},"source":["# Part III. API Sequential de Pytorch\n","\n","La Parte II presentó la API Module de PyTorch, que le permite definir capas de aprendizaje arbitrarias y su conectividad.\n","\n","Para modelos simples como una serie de capas apiladas, aún necesita seguir 3 pasos: generar una subclase de `nn.Module`, asignar capas a atributos de clase en` __init__`, y llamar a cada capa una por una en `forward ()`. ¿Existe una forma más conveniente?\n","\n","Afortunadamente, PyTorch proporciona un contenedor subclase de Module llamado `nn.Sequential`, que fusiona los pasos anteriores en uno. No es tan flexible como `nn.Module`, porque no puede especificar una topología más compleja que una serie de capas apiladas, pero es lo suficientemente bueno para muchos casos de uso.\n","\n","### API Sequential: MLP de Dos Capas\n","Veamos cómo reescribir nuestro ejemplo de MLP de dos capas con `nn.Sequential`, y entrenarlo usando el ciclo de entrenamiento definido anteriormente.\n","\n","Nuevamente, no tenés que ajustar ningún hiperparámetro acá, pero deberías lograr una precisión superior al 40% después de una época de entrenamiento. "]},{"cell_type":"code","metadata":{"id":"mxo5bVSowhf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619637416983,"user_tz":180,"elapsed":10323,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"9dc291ad-87dd-4d13-948e-acaee40dd899"},"source":["# Necesitamos envolver la función `flatten` en un Module para apilarlo\n","# en nn.Sequential\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        return flatten(x)\n","\n","hidden_layer_size = 4000\n","learning_rate = 1e-2\n","\n","model = nn.Sequential(\n","    Flatten(),\n","    nn.Linear(3 * 32 * 32, hidden_layer_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_layer_size, 10),\n",")\n","\n","# podés utilizar el momentum de Nesterov en optim.SGD\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","train_part34(model, optimizer)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch 0\n","Iteration 0, loss = 2.2379\n","Checking accuracy on validation set\n","Got 174 / 1000 correct (17.40)\n","\n","Iteration 100, loss = 1.8056\n","Checking accuracy on validation set\n","Got 409 / 1000 correct (40.90)\n","\n","Iteration 200, loss = 1.8013\n","Checking accuracy on validation set\n","Got 410 / 1000 correct (41.00)\n","\n","Iteration 300, loss = 1.7069\n","Checking accuracy on validation set\n","Got 398 / 1000 correct (39.80)\n","\n","Iteration 400, loss = 1.6308\n","Checking accuracy on validation set\n","Got 434 / 1000 correct (43.40)\n","\n","Iteration 500, loss = 1.9919\n","Checking accuracy on validation set\n","Got 440 / 1000 correct (44.00)\n","\n","Iteration 600, loss = 1.6775\n","Checking accuracy on validation set\n","Got 459 / 1000 correct (45.90)\n","\n","Iteration 700, loss = 1.8867\n","Checking accuracy on validation set\n","Got 416 / 1000 correct (41.60)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A55hF-vswhf7"},"source":["### API Sequential: CNN de 3 capas\n","Acá tenés que usar `nn.Sequential` para definir y entrenar una CNN de tres capas con la misma arquitectura que usamos en la Parte II:\n","\n","1. Capa convolucional (con sesgo) con 32 filtros de 5x5, con padding de 2\n","2. ReLU\n","3. Capa convolucional (con sesgo) con 16 filtros 3x3, con padding de 1\n","4. ReLU\n","5. Capa densa (con sesgo) para calcular las puntuaciones de 10 clases\n","\n","Tenés que optimizar tu modelo usando el descenso de gradiente estocástico con el momentum de Nesterov en 0.9.\n","\n","De nuevo, no necesitás ajustar ningún hiperparámetro, pero deberías ver un accuracy superior al 55% después de una época de entrenamiento. "]},{"cell_type":"code","metadata":{"id":"sequential_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619638396142,"user_tz":180,"elapsed":10696,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"9424a295-d2c3-4786-ea49-07c95db8a8e6"},"source":["channel_1 = 32\n","channel_2 = 16\n","learning_rate = 1e-2\n","\n","model = None\n","optimizer = None\n","\n","#############################################################################\n","# TODO: Reescribí la CNN de 3 capas con sesgo de la Parte II con la         #\n","# API Sequential.                                                           #\n","#############################################################################\n","# ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) ***** \n","\n","in_channel = 3\n","num_classes = 10\n","\n","# Definición del Modelo:\n","model = nn.Sequential(\n","    nn.Conv2d(in_channel, channel_1, kernel_size=5, padding=2),\n","    nn.ReLU(),\n","    nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1),\n","    Flatten(),\n","    nn.Linear(16*32*32, num_classes)\n",")\n","\n","# Definición del Optimizador:\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n","                     momentum=0.9, nesterov=True)\n","\n","# ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****       #\n","#############################################################################\n","#                          FINAL DE TU CÓDIGO                               #       \n","#############################################################################\n","\n","train_part34(model, optimizer)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Epoch 0\n","Iteration 0, loss = 2.3046\n","Checking accuracy on validation set\n","Got 175 / 1000 correct (17.50)\n","\n","Iteration 100, loss = 1.4224\n","Checking accuracy on validation set\n","Got 442 / 1000 correct (44.20)\n","\n","Iteration 200, loss = 1.2989\n","Checking accuracy on validation set\n","Got 456 / 1000 correct (45.60)\n","\n","Iteration 300, loss = 1.4116\n","Checking accuracy on validation set\n","Got 492 / 1000 correct (49.20)\n","\n","Iteration 400, loss = 1.4421\n","Checking accuracy on validation set\n","Got 480 / 1000 correct (48.00)\n","\n","Iteration 500, loss = 1.4615\n","Checking accuracy on validation set\n","Got 570 / 1000 correct (57.00)\n","\n","Iteration 600, loss = 1.3785\n","Checking accuracy on validation set\n","Got 554 / 1000 correct (55.40)\n","\n","Iteration 700, loss = 1.2691\n","Checking accuracy on validation set\n","Got 561 / 1000 correct (56.10)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lY95QlZewhf8"},"source":["# Parte III. Desafío abierto de CIFAR-10\n","\n","En esta sección, podés experimentar con cualquier arquitectura CNN que desee en CIFAR-10.\n","\n","Ahora es tu trabajo experimentar con arquitecturas, hiperparámetros, funciones de pérdida y optimizadores para entrenar un modelo que logre ** al menos un 70% ** de accuracy en el conjunto de validación de CIFAR-10 en 10 épocas. Podés utilizar las funciones check_accuracy y train que ya definimos más arriba. Podés utilizar la API `nn.Module` o` nn.Sequential`.\n","\n","Describí lo que hiciste al final de este notebook.\n","\n","Acá está la documentación oficial de la API para cada componente. \n","\n","* Capas en el paquete torch.nn: http://pytorch.org/docs/stable/nn.html\n","* Activaciones: http://pytorch.org/docs/stable/nn.html#non-linear-activations\n","* Funciones de pérdida: http://pytorch.org/docs/stable/nn.html#loss-functions\n","* Optimizadores: http://pytorch.org/docs/stable/optim.html\n","\n","\n","### Cosas que podrías probar:\n","- ** Tamaño de kernel **: arriba usamos 5x5; ¿Serían más eficientes los kernels más pequeños?\n","- ** Número de kernels **: arriba usamos 32 kernels. ¿Más o menos lo hacen mejor?\n","- ** Pooling vs Strided Convolution **: ¿Utilizas el pooling máximo o simplemente convoluciones con stride?\n","- ** Normalización por lotes **: intente agregar la normalización por lotes espacial después de las capas de convolución ¿Tus redes se entrenan más rápido?\n","- ** Arquitectura de red **: la red anterior tiene dos capas de parámetros entrenables. ¿Puede hacerlo mejor con una red profunda? Las buenas arquitecturas para probar incluyen:\n","    - [conv-relu-pool]xN -> [afín]xM -> [softmax o SVM]\n","    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax o SVM]\n","    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax o SVM]\n","- ** Pooling promedio global **: en lugar de aplanar y luego tener varias capas afines, realice convoluciones hasta que su imagen se vuelva pequeña (7x7 más o menos) y luego realice una operación de pooling promedio para obtener una imagen de imagen 1x1 (1, 1, Filter #), que luego se transforma en un vector (Filter #). Esto se utiliza en la [Red Inception de Google] (https://arxiv.org/abs/1512.00567) (consulte la Tabla 1 para conocer su arquitectura).\n","- ** Regularización **: agregue regularización de pesos, o tal vez Dropout.\n","\n","### Consejos para el entrenamiento\n","Para cada arquitectura de red que pruebe, debe ajustar la tasa de aprendizaje y otros hiperparámetros. Al hacer esto, hay un par de cosas importantes a tener en cuenta:\n","\n","- Si los hiperparámetros funcionan bien, deberías ver una mejora en unos pocos cientos de iteraciones\n","- Recordá el enfoque de grueso a fino para el ajuste de hiperparámetros: comenzá probando una amplia gama de hiperparámetros para solo unas pocas iteraciones de entrenamiento para encontrar las combinaciones de parámetros que funcionan.\n","- Una vez que hayas encontrado algunos conjuntos de hiperparámetros que parecen funcionar, buscá con más precisión alrededor de estos hiperparámetros. Puede que tengas que entrenar para más épocas.\n","- Tenés que utilizar el conjunto de validación para la búsqueda de hiperparámetros y guardarte el conjunto de prueba para evaluar tu arquitectura con los mejores parámetros seleccionados por el conjunto de validación.\n","\n","### Ir más allá\n","Si te sentís aventurero, hay muchas otras features que podés implementar para intentar mejorar tu rendimiento. ** No es necesario ** que implementes ninguno de estos, ¡pero no te perdás la diversión si tenés tiempo!\n","\n","- Optimizadores alternativos: podés probar Adam, Adagrad, RMSprop, etc.\n","- Funciones de activación alternativas como Leaky ReLU, PReLU, ELU o MaxOut.\n","- Aumento de datos\n","- Nuevas arquitecturas\n","  - [ResNets] (https://arxiv.org/abs/1512.03385) donde la entrada de la capa anterior se agrega a la salida.\n","  - [DenseNets] (https://arxiv.org/abs/1608.06993) donde las entradas de las capas anteriores se concatenan juntas.\n","  - [Este blog tiene una descripción detallada] (https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n","\n","### ¡Divertite y feliz entrenamiento!"]},{"cell_type":"code","metadata":{"id":"open_ended_accuracy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619643904156,"user_tz":180,"elapsed":110535,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"ce2bf988-5445-444b-b955-599e8788c91f"},"source":["################################################################################\n","# TODO:                                                                        #         \n","# Experimentá con arquitecturas, optimizadores e hiperparámetros.              #\n","# Logre AL MENOS 70% de accuracy en el conjunto de validación en 10 épocas.    #\n","#                                                                              #\n","# Tené en cuenta que podés usar la función check_accuracy para evaluar tanto   #\n","# el conjunto de prueba como el conjunto de validación, pasando loader_test o  #\n","# loader_val como segundo argumento para check_accuracy. No deberías tocar el  #\n","# conjunto de prueba hasta que hayas elegido tu arquitectura e hiperparámetros.#\n","# Solo usás el conjunto de prueba una vez para informar un puntaje al final    #\n","################################################################################\n","model = None\n","optimizer = None\n","#############################################################################\n","# ***** INICIO DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) ***** \n","\n","class Desafio_CNN_V1(nn.Module):\n","    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n","        super().__init__()\n","        # Capa convolucional 1:\n","        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size=3, padding=3)\n","        nn.init.kaiming_normal_(self.conv1.weight)\n","        # Capa convolucional 2:\n","        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1)\n","        nn.init.kaiming_normal_(self.conv2.weight)\n","        # Capa densa:\n","        self.fc1 = nn.Linear(16*9*9, num_classes) # Hardcodeado el input (luego de correr y que tire error)\n","        nn.init.kaiming_normal_(self.fc1.weight)\n","        # Capas de Batch Normalization:\n","        self.batchnorm1 = nn.BatchNorm2d(channel_1)\n","        self.batchnorm2 = nn.BatchNorm2d(channel_2)\n","        # Capas de Max Pooling:\n","        self.maxPool1 = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n","\n","    def forward(self, x):\n","        #print(x.shape) # Descomentar para poder hardcodear las funciones de arriba\n","        x = F.relu(self.conv1(x))\n","        #print(x.shape)        \n","        x = self.maxPool1(x)\n","        #print(x.shape)\n","        x = self.batchnorm1(x)\n","        #print(x.shape)\n","        x = F.relu(self.conv2(x))\n","        #print(x.shape)\n","        x = self.maxPool1(x)\n","        #print(x.shape)\n","        x = self.batchnorm2(x)\n","        #print(x.shape)\n","        x = flatten(x)\n","        #print(x.shape)\n","        scores = self.fc1(x)\n","        return scores\n","\n","################################################################################\n","class Desafio_CNN_V2(nn.Module):\n","    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n","        super().__init__()\n","        # Capa convolucional 1:\n","        self.conv1 = nn.Conv2d(in_channel, channel_1, kernel_size=3, padding=3)\n","        nn.init.kaiming_normal_(self.conv1.weight)\n","        # Capa convolucional 2:\n","        self.conv2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1)\n","        nn.init.kaiming_normal_(self.conv2.weight)\n","        # Capa convolucional 3:\n","        self.conv3 = nn.Conv2d(32, 18, kernel_size=3, padding=3) # Hardcodeado el input (luego de correr y que tire error)\n","        nn.init.kaiming_normal_(self.conv1.weight)\n","        # Capa convolucional 4:\n","        self.conv4 = nn.Conv2d(18, 32, kernel_size=3, padding=3) # Hardcodeado el input (luego de correr y que tire error)     \n","        self.batchnorm4 = nn.BatchNorm2d(32)\n","        # Capa densa:\n","        self.fc1 = nn.Linear(16*8*8, num_classes) # Hardcodeado el input (luego de correr y que tire error)\n","        nn.init.kaiming_normal_(self.fc1.weight)\n","        # Capas de Batch Normalization:\n","        self.batchnorm1 = nn.BatchNorm2d(channel_1)\n","        self.batchnorm2 = nn.BatchNorm2d(channel_2)\n","        self.batchnorm3 = nn.BatchNorm2d(18) # Hardcodeado el input (luego de correr y que tire error)\n","        # Capas de Max Pooling: \n","        self.maxPool1 = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n","\n","        #self.fc1 = nn.Linear(16*8*8, num_classes)\n","        #nn.init.kaiming_normal_(self.fc1.weight)\n","\n","    def forward(self, x):\n","        #print(x.shape)\n","        x = F.relu(self.conv1(x))\n","        #print(x.shape)        \n","        x = self.maxPool1(x)\n","        #print(x.shape)\n","        x = self.batchnorm1(x)\n","        #print(x.shape)\n","        x = F.relu(self.conv3(x))\n","        #print(x.shape)\n","        x = self.maxPool1(x)\n","        #print(x.shape)\n","        x = self.batchnorm3(x)\n","        #print(x.shape)\n","        x = F.relu(self.conv4(x))\n","        #print(x.shape)\n","        x = self.batchnorm4(x)\n","        #print(x.shape)\n","        x = F.relu(self.conv2(x))\n","        #print(x.shape)\n","        x = self.maxPool1(x)\n","        #print(x.shape)\n","        x = self.batchnorm2(x)\n","        #print(x.shape)\n","        x = flatten(x)\n","        #print(x.shape)\n","        scores = self.fc1(x)\n","        return scores\n","################################################################################\n","\n","model = Desafio_CNN_V2(in_channel=3, channel_1=32, channel_2=16, num_classes=10) # Harcodear TresCapasCNN: cambiar entrada de capa densa a: 8*32*32\n","\n","#Optimizador\n","learning_rate = 1e-2\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n","\n","# ***** FINAL DE TU CÓDIGO (NO BORRES NI MODIFIQUES ESTA LÍNEA) *****       #\n","#############################################################################\n","#                          FINAL DE TU CÓDIGO                               #       \n","#############################################################################\n","\n","# Tenés que llegar a un 70% de accuracy\n","train_part34(model, optimizer, epochs=10)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Epoch 0\n","Iteration 0, loss = 3.1695\n","Checking accuracy on validation set\n","Got 111 / 1000 correct (11.10)\n","\n","Iteration 100, loss = 1.5982\n","Checking accuracy on validation set\n","Got 480 / 1000 correct (48.00)\n","\n","Iteration 200, loss = 1.0667\n","Checking accuracy on validation set\n","Got 549 / 1000 correct (54.90)\n","\n","Iteration 300, loss = 1.1112\n","Checking accuracy on validation set\n","Got 607 / 1000 correct (60.70)\n","\n","Iteration 400, loss = 1.1837\n","Checking accuracy on validation set\n","Got 592 / 1000 correct (59.20)\n","\n","Iteration 500, loss = 1.0848\n","Checking accuracy on validation set\n","Got 645 / 1000 correct (64.50)\n","\n","Iteration 600, loss = 1.1213\n","Checking accuracy on validation set\n","Got 640 / 1000 correct (64.00)\n","\n","Iteration 700, loss = 0.8753\n","Checking accuracy on validation set\n","Got 636 / 1000 correct (63.60)\n","\n","Epoch 1\n","Iteration 0, loss = 0.7553\n","Checking accuracy on validation set\n","Got 651 / 1000 correct (65.10)\n","\n","Iteration 100, loss = 0.9110\n","Checking accuracy on validation set\n","Got 654 / 1000 correct (65.40)\n","\n","Iteration 200, loss = 0.9592\n","Checking accuracy on validation set\n","Got 652 / 1000 correct (65.20)\n","\n","Iteration 300, loss = 0.8364\n","Checking accuracy on validation set\n","Got 679 / 1000 correct (67.90)\n","\n","Iteration 400, loss = 0.7778\n","Checking accuracy on validation set\n","Got 652 / 1000 correct (65.20)\n","\n","Iteration 500, loss = 0.8529\n","Checking accuracy on validation set\n","Got 676 / 1000 correct (67.60)\n","\n","Iteration 600, loss = 0.7300\n","Checking accuracy on validation set\n","Got 692 / 1000 correct (69.20)\n","\n","Iteration 700, loss = 1.0706\n","Checking accuracy on validation set\n","Got 678 / 1000 correct (67.80)\n","\n","Epoch 2\n","Iteration 0, loss = 0.9421\n","Checking accuracy on validation set\n","Got 687 / 1000 correct (68.70)\n","\n","Iteration 100, loss = 1.0248\n","Checking accuracy on validation set\n","Got 711 / 1000 correct (71.10)\n","\n","Iteration 200, loss = 0.8961\n","Checking accuracy on validation set\n","Got 712 / 1000 correct (71.20)\n","\n","Iteration 300, loss = 0.9419\n","Checking accuracy on validation set\n","Got 688 / 1000 correct (68.80)\n","\n","Iteration 400, loss = 0.7447\n","Checking accuracy on validation set\n","Got 719 / 1000 correct (71.90)\n","\n","Iteration 500, loss = 0.9020\n","Checking accuracy on validation set\n","Got 701 / 1000 correct (70.10)\n","\n","Iteration 600, loss = 0.7013\n","Checking accuracy on validation set\n","Got 714 / 1000 correct (71.40)\n","\n","Iteration 700, loss = 0.7686\n","Checking accuracy on validation set\n","Got 718 / 1000 correct (71.80)\n","\n","Epoch 3\n","Iteration 0, loss = 0.7843\n","Checking accuracy on validation set\n","Got 724 / 1000 correct (72.40)\n","\n","Iteration 100, loss = 0.8236\n","Checking accuracy on validation set\n","Got 722 / 1000 correct (72.20)\n","\n","Iteration 200, loss = 0.6319\n","Checking accuracy on validation set\n","Got 724 / 1000 correct (72.40)\n","\n","Iteration 300, loss = 0.5787\n","Checking accuracy on validation set\n","Got 716 / 1000 correct (71.60)\n","\n","Iteration 400, loss = 0.7952\n","Checking accuracy on validation set\n","Got 710 / 1000 correct (71.00)\n","\n","Iteration 500, loss = 0.6783\n","Checking accuracy on validation set\n","Got 727 / 1000 correct (72.70)\n","\n","Iteration 600, loss = 0.8489\n","Checking accuracy on validation set\n","Got 720 / 1000 correct (72.00)\n","\n","Iteration 700, loss = 0.6368\n","Checking accuracy on validation set\n","Got 741 / 1000 correct (74.10)\n","\n","Epoch 4\n","Iteration 0, loss = 0.5918\n","Checking accuracy on validation set\n","Got 730 / 1000 correct (73.00)\n","\n","Iteration 100, loss = 0.7290\n","Checking accuracy on validation set\n","Got 721 / 1000 correct (72.10)\n","\n","Iteration 200, loss = 0.6630\n","Checking accuracy on validation set\n","Got 736 / 1000 correct (73.60)\n","\n","Iteration 300, loss = 0.5762\n","Checking accuracy on validation set\n","Got 733 / 1000 correct (73.30)\n","\n","Iteration 400, loss = 0.7732\n","Checking accuracy on validation set\n","Got 731 / 1000 correct (73.10)\n","\n","Iteration 500, loss = 0.8959\n","Checking accuracy on validation set\n","Got 727 / 1000 correct (72.70)\n","\n","Iteration 600, loss = 0.7666\n","Checking accuracy on validation set\n","Got 737 / 1000 correct (73.70)\n","\n","Iteration 700, loss = 0.7488\n","Checking accuracy on validation set\n","Got 731 / 1000 correct (73.10)\n","\n","Epoch 5\n","Iteration 0, loss = 0.7487\n","Checking accuracy on validation set\n","Got 718 / 1000 correct (71.80)\n","\n","Iteration 100, loss = 0.4903\n","Checking accuracy on validation set\n","Got 716 / 1000 correct (71.60)\n","\n","Iteration 200, loss = 0.5942\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 300, loss = 0.5968\n","Checking accuracy on validation set\n","Got 723 / 1000 correct (72.30)\n","\n","Iteration 400, loss = 0.7396\n","Checking accuracy on validation set\n","Got 716 / 1000 correct (71.60)\n","\n","Iteration 500, loss = 0.5556\n","Checking accuracy on validation set\n","Got 728 / 1000 correct (72.80)\n","\n","Iteration 600, loss = 0.5875\n","Checking accuracy on validation set\n","Got 740 / 1000 correct (74.00)\n","\n","Iteration 700, loss = 0.8918\n","Checking accuracy on validation set\n","Got 739 / 1000 correct (73.90)\n","\n","Epoch 6\n","Iteration 0, loss = 0.6553\n","Checking accuracy on validation set\n","Got 743 / 1000 correct (74.30)\n","\n","Iteration 100, loss = 0.4408\n","Checking accuracy on validation set\n","Got 738 / 1000 correct (73.80)\n","\n","Iteration 200, loss = 0.3728\n","Checking accuracy on validation set\n","Got 725 / 1000 correct (72.50)\n","\n","Iteration 300, loss = 0.6450\n","Checking accuracy on validation set\n","Got 731 / 1000 correct (73.10)\n","\n","Iteration 400, loss = 0.6006\n","Checking accuracy on validation set\n","Got 741 / 1000 correct (74.10)\n","\n","Iteration 500, loss = 0.6393\n","Checking accuracy on validation set\n","Got 721 / 1000 correct (72.10)\n","\n","Iteration 600, loss = 0.6239\n","Checking accuracy on validation set\n","Got 733 / 1000 correct (73.30)\n","\n","Iteration 700, loss = 0.7182\n","Checking accuracy on validation set\n","Got 724 / 1000 correct (72.40)\n","\n","Epoch 7\n","Iteration 0, loss = 0.4002\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 100, loss = 0.6930\n","Checking accuracy on validation set\n","Got 727 / 1000 correct (72.70)\n","\n","Iteration 200, loss = 0.6195\n","Checking accuracy on validation set\n","Got 729 / 1000 correct (72.90)\n","\n","Iteration 300, loss = 0.5679\n","Checking accuracy on validation set\n","Got 745 / 1000 correct (74.50)\n","\n","Iteration 400, loss = 0.7091\n","Checking accuracy on validation set\n","Got 730 / 1000 correct (73.00)\n","\n","Iteration 500, loss = 0.5487\n","Checking accuracy on validation set\n","Got 732 / 1000 correct (73.20)\n","\n","Iteration 600, loss = 0.6012\n","Checking accuracy on validation set\n","Got 743 / 1000 correct (74.30)\n","\n","Iteration 700, loss = 0.6076\n","Checking accuracy on validation set\n","Got 733 / 1000 correct (73.30)\n","\n","Epoch 8\n","Iteration 0, loss = 0.7448\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 100, loss = 0.5770\n","Checking accuracy on validation set\n","Got 735 / 1000 correct (73.50)\n","\n","Iteration 200, loss = 0.6155\n","Checking accuracy on validation set\n","Got 758 / 1000 correct (75.80)\n","\n","Iteration 300, loss = 0.4757\n","Checking accuracy on validation set\n","Got 746 / 1000 correct (74.60)\n","\n","Iteration 400, loss = 0.6095\n","Checking accuracy on validation set\n","Got 745 / 1000 correct (74.50)\n","\n","Iteration 500, loss = 0.5670\n","Checking accuracy on validation set\n","Got 736 / 1000 correct (73.60)\n","\n","Iteration 600, loss = 0.4807\n","Checking accuracy on validation set\n","Got 739 / 1000 correct (73.90)\n","\n","Iteration 700, loss = 0.5231\n","Checking accuracy on validation set\n","Got 746 / 1000 correct (74.60)\n","\n","Epoch 9\n","Iteration 0, loss = 0.4858\n","Checking accuracy on validation set\n","Got 732 / 1000 correct (73.20)\n","\n","Iteration 100, loss = 0.6805\n","Checking accuracy on validation set\n","Got 739 / 1000 correct (73.90)\n","\n","Iteration 200, loss = 0.7820\n","Checking accuracy on validation set\n","Got 752 / 1000 correct (75.20)\n","\n","Iteration 300, loss = 0.6376\n","Checking accuracy on validation set\n","Got 741 / 1000 correct (74.10)\n","\n","Iteration 400, loss = 0.5879\n","Checking accuracy on validation set\n","Got 742 / 1000 correct (74.20)\n","\n","Iteration 500, loss = 0.6866\n","Checking accuracy on validation set\n","Got 737 / 1000 correct (73.70)\n","\n","Iteration 600, loss = 0.5780\n","Checking accuracy on validation set\n","Got 739 / 1000 correct (73.90)\n","\n","Iteration 700, loss = 0.5385\n","Checking accuracy on validation set\n","Got 727 / 1000 correct (72.70)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"tags":["pdf-inline"],"id":"QQ5bZMHuwhf_"},"source":["## Describí lo que hiciste\n","\n","En la celda a continuación, tenés que escribir una explicación de lo que hiciste, las funciones adicionales que implementaste y / o los gráficos que realizaste en el proceso de entrenamiento y evaluación de tu red."]},{"cell_type":"markdown","metadata":{"id":"ia9wIv08TTjH"},"source":["**COMENTARIOS**\n","- Se diseñó el modelo `Desafio_CNN_V1`. Con este modelo se probaron diferentes valores de `learning_rate`. Se observó que valores del orden de `learning_rate = 1e-4` dejan lejos del accuracy deseado en solo 10 épocas (quizás se necesiten mayor cantidad de épocas, esto no se probó). Valores próximos a `learning_rate = 1e-2` hacen crecer rápido la precisión en las primeras épocas pero al finalizar el proceso no llega al 70% buscado, quedando en el orden del 65 a 68%.\n","- Por este motivo se propone el modelo `Desafio_CNN_V2`. Con este modelo se dejó fijo el `learning_rate = 1e-2` y se probó la incorporación de mayor cantidad de capas. Lo que se observa básicamente es que repetir una **capa convolucional + relu** luego de aplicar la tríada: **capa convolucional + máx pooling + batch normalization**, hace crecer la precisión del modelo. Con este modelo se alcanzaron preciciones del orden del 73% al 76%.\n","- No se emplearon gráficos ya que luego de TP3, pareció engorroso el proceso de incorporación y su posterior visualización. El ajuste se mejoró visualizando las salidas en pantalla."]},{"cell_type":"markdown","metadata":{"id":"l52Y7_SuwhgB"},"source":["## Conjunto de prueba: ejecute esto solo una vez\n","\n","Ahora que obtuvimos un resultado con el que estamos contentos, probamos nuestro modelo final en el conjunto de prueba (que debeés almacenar en best_model). Pensá en cómo se compara esto con la precisión de tu conjunto de validación."]},{"cell_type":"code","metadata":{"id":"HQ8TgtESwhgC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619644541775,"user_tz":180,"elapsed":2682,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"135ba010-f6ef-4753-f88e-2e37ff384740"},"source":["best_model = model\n","check_accuracy_part34(loader_test, best_model)"],"execution_count":71,"outputs":[{"output_type":"stream","text":["Checking accuracy on test set\n","Got 7482 / 10000 correct (74.82)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hYmIZ24nVrc7"},"source":["Accuracy obtenido: **74.82%**"]}]}