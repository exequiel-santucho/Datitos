{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TP3-ExequielSantucho-DATITOS","provenance":[{"file_id":"1tFdjNGWOoaSNpr2f7MHcSVVKOBtdPZxs","timestamp":1618856642826}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"rmdirHcPShyn"},"source":["#@title Aprendizaje Profundo | Otoño 2021 by Datitos{display-mode: \"form\" }\n","#@markdown ![71335171.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAACwElEQVR4nOzdMY7iQBBA0WU197/FnJNNJ/FqWvLHZfd7McIGfVVQos3X+/3+A2f7e/UN8EzCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBJfV9/A/7xer6XX3/1/gZ70eU0sEsIiISwSwiIhLBLCIiEsEiP2WEf7m9U9zVnvU9vh85pYJIRFQlgkhEVCWCSERUJYJEbssc5ytL+5at8zec9UM7FICIuEsEgIi4SwSAiLhLBIPGqPdWR1v1VfdwcmFglhkRAWCWGREBYJYZEQFokt9lhHdt4z1UwsEsIiISwSwiIhLBLCIiEsEh/dY+18zq4w7RzlTyYWCWGREBYJYZEQFglhkRAWiS1+jzVhr/Mbd7nP3zCxSAiLhLBICIuEsEgIi4SwSDxqj1U/72r1ulc9l2sCE4uEsEgIi4SwSAiLhLBICIvE7D3W9/fSy6/63dLqdZfvc/F7mMDEIiEsEsIiISwSwiIhLBLCIjF7j3WSs87rTXufyUwsEsIiISwSwiIhLBLCIiEsEq8Ju5N6r3OXc3xP2oeZWCSERUJYJIRFQlgkhEVCWCRG7LGOTN7TfNIdvwcTi4SwSAiLhLBICIuEsEgIi8Toc4U7Pyf9p8n7qiMmFglhkRAWCWGREBYJYZEQFonRe6wjd9zr7MbEIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIiISwSwiIhLBLCIiEsEsIi8S8AAP//HtRtH09JwIEAAAAASUVORK5CYII=)\n","#El siguiente notebook fue diseñado por Pablo Marinozi como el primer trabajo práctico correspondiente a la versión de Otoño del 2021 del curso Aprendizaje Profundo organizado por Datitos \n","#Para mayor información consultar https://datitos.github.io/curso-aprendizaje-profundo/#calendario"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVd9DgFBSWXj"},"source":["# Trabajo Práctico N°3: Overfitting y Underfitting"]},{"cell_type":"markdown","metadata":{"id":"RswOqhTSS73W"},"source":["Este trabajo práctico tiene 2 partes.\n","\n","La primera parte consiste en un mini tutorial para aprender a usar TensorBoard. Esta herramienta que nos permite visualizar e interpretar el entrenamiento de nuestros modelos a partir de una página web.\n","\n","La segunda parte consiste en verificar de manera práctica la correlación entre la complejidad de un modelo y la presencia de underfitting y overfitting.\n"]},{"cell_type":"markdown","metadata":{"id":"m-xLWrwFXFIK"},"source":["## Parte 1: Tutorial de TensorBoard en Pytorch"]},{"cell_type":"markdown","metadata":{"id":"i6yrpzClXnzy"},"source":["TensorBoard es un kit de herramientas de visualización para la experimentación del aprendizaje automático.\n","\n","TensorBoard permite rastrear y visualizar métricas como las funciones de pérdida y el accuracy, el grafo computacional del modelo, histogramas, imágenes y mucho más.\n","\n","En este tutorial, cubriremos la instalación de TensorBoard,\n","uso básico con PyTorch y cómo visualizar los datos que generamos en la interfaz de usuario de TensorBoard."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmxlSr-_aLoL","executionInfo":{"status":"ok","timestamp":1618881818376,"user_tz":180,"elapsed":8482,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"2911dbc4-a6ef-4823-d37f-e0d4939ed9d1"},"source":["!pip install torch torchvision\n","import torch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FqrXfdI2YGtb"},"source":["### Summary Writer\n","\n","Los `SummaryWriter` son clases de Tensorboard que se encargan de generar, durante el entrenamiento, los registros necesarios para poder visualizar el progreso del modelo."]},{"cell_type":"code","metadata":{"id":"GKvSXcxzYB6H"},"source":["from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fem1nRblYzVV"},"source":["Por defecto, las instancias de esta clase guardarán todos los registros en la carpeta `./runs/`"]},{"cell_type":"markdown","metadata":{"id":"PiRO6wPzZJl6"},"source":["### Registros de escalares\n","\n","En el aprendizaje automático, es importante comprender métricas clave como la función de pérdida y cómo cambian durante el entrenamiento. `Scalar` ayuda a guardar el valor de la función de pérdida de cada época de entrenamiento. También puede guardar otras métricas como el accuracy.\n","\n","Para registrar un valor escalar, usaremos `add_scalar(etiqueta, scalar_value, global_step = None, walltime = None)`. Por ejemplo, creemos un bucle de entrenamiento para una regresión lineal simple y registremos el valor de la función de pérdida pérdida usando add_scalar."]},{"cell_type":"code","metadata":{"id":"J42PZQ2OZ_Lh"},"source":["x = torch.arange(-5, 5, 0.1).view(-1, 1)\n","y = -5 * x + 0.1 * torch.randn(x.size())\n","\n","model = torch.nn.Linear(1, 1)\n","criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n","\n","def train_model(iter):\n","    for epoch in range(iter):\n","        y1 = model(x)\n","        loss = criterion(y1, y)\n","        writer.add_scalar(\"Loss/train\", loss, epoch)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","train_model(10)\n","writer.flush()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O5-OHcjGaaWT"},"source":["Llamamos al método `flush()` para asegurarnos de que todos los eventos pendientes se hayan escrito en el disco.\n","\n","Te recomendamos revisar los tutoriales de [torch.utils.tensorboard](https://pytorch.org/docs/stable/tensorboard.html) para encontrar más tipos de visualización de TensorBoard que se puedan registrar.\n","\n","Si ya no necesitamos al `SummaryWriter`, llamemos al método `close()`. "]},{"cell_type":"code","metadata":{"id":"IRSe6eHcFPyT"},"source":["writer.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hr9sv-KCa8ZC"},"source":["### Ejecutar Tensorboard\n","\n","Para visualizar los datos que hemos registrado, debemos instalar TensorBoard a través de la línea de comando. "]},{"cell_type":"code","metadata":{"id":"oHbw_QnnFyON","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618881949555,"user_tz":180,"elapsed":3273,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"503b53f4-ef62-4a02-89d3-5aad8df50790"},"source":["!pip install tensorboard"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.4.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.4)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (54.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.32.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.28.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (3.10.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k_1gdoywbk6m"},"source":["Ahora, iniciaremos TensorBoard, especificando el directorio raíz de los registros que usamos anteriormente. El argumento `logdir` apunta al directorio donde TensorBoard buscará archivos de registros que pueda mostrar. TensorBoard recorrerá de forma recursiva la estructura de directorios enraizada en `logdir`, buscando archivos con extensión `.tfevents`. "]},{"cell_type":"code","metadata":{"id":"P-qupXpbGH8k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618882396027,"user_tz":180,"elapsed":174986,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"c6d219a6-4652-407c-d5cf-69d9baea322b"},"source":["!tensorboard --logdir=runs"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-20 01:30:21.824135: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n","TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n","^C\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Jjdy5txcDZN"},"source":["Si todo salió bien, al ejecutar la celda anterior obtendremos una dirección url y notaremos que la ejecución no se detiene. Esto es así porque esa celda está publicando una interfaz gráfica interactiva en el puerto local accesible desde esa url. Si estamos trabajando en nuestra máquina local, podremos hacer click sobre el enlace y acceder a una pantalla como esta. <img src=\"https://raw.githubusercontent.com/pytorch/tutorials/master/_static/img/thumbnails/tensorboard_scalars.png\" width=\"700\"/>"]},{"cell_type":"markdown","metadata":{"id":"6x80GyOMc2hs"},"source":["Por el contrario, si estamos trabajando en Google Colab, no podremos acceder a la página que nos muestra el enlace porque apunta a un puerto local (el 6006) de nuestra máquina local, en lugar de al puerto de la máquina virtual que nos provee Google donde está corriendo el servicio. \n","\n","Para solucionar este problema debemos instalar ***ngrok***. Esta herramienta nos permite exponer a internet una URL generada dinámicamente, la cual apunta a un servicio web que se está ejecutando en el localhost de alguna máquina. Esto es justo lo que necesitamos.\n","\n","A continuacion, detenga la celda que está ejecutando TensorBoard y ejecute la siguiente para llevar adelante la instalación."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TU8ZJXEsS226","executionInfo":{"status":"ok","timestamp":1618882156409,"user_tz":180,"elapsed":41798,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"01134645-d384-4046-8cab-582c3a5c970f"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-20 01:28:34--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 34.235.106.23, 54.159.124.229, 52.70.180.11, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|34.235.106.23|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13828408 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n","\n","ngrok-stable-linux- 100%[===================>]  13.19M  16.3MB/s    in 0.8s    \n","\n","2021-04-20 01:28:35 (16.3 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13828408/13828408]\n","\n","Archive:  ngrok-stable-linux-amd64.zip\n","replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n","  inflating: ngrok                   \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sQQhz165eoI4"},"source":["Ahora ejecute la siguiente celda que contiene el código necesario para crear el tunel entre el puerto 6006 de la máquina virtual y una url dinámica creada en el momento."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZvHbH5McTK_7","executionInfo":{"status":"ok","timestamp":1618882161924,"user_tz":180,"elapsed":747,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"d068e06e-9176-4ced-a22e-3c1a86c63e2b"},"source":["import os\n","LOG_DIR = 'runs'\n","os.makedirs(LOG_DIR, exist_ok=True)\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR))\n","get_ipython().system_raw('./ngrok http 6006 &')\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["http://54dcf1710b28.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jMC7qwowfEp0"},"source":["Si todo salió bien, en este momento deberíamos poder hacer click en el enlace que arrojó la celda anterior y nos derivará a una página vacía con un mensaje de error que indica que no se pudo conectar al puerto. Esto quiere decir que el tunel fue creado correctamente, pero no hay ningún servicio corriendo en el puerto al que conecta. Para arreglarlo debemos volver a ejecutar la celda que inicia el proceso de tensorboard y volver a ingresar a la url que nos arrojó ngrok. (ejecutar celda con \"!tensorboard --logdir=runs\" y recargar la página abierta con el link de ngrok.io)\n","\n","En el caso de que hayas ejecutado la celda y te largue un error en lugar de la url, simplemente vuelve a ejecutarla hasta que funcione."]},{"cell_type":"markdown","metadata":{"id":"qSzGw3mIguIu"},"source":["## Parte 2: Complejidad del modelo, overfitting y underfitting"]},{"cell_type":"markdown","metadata":{"id":"DZFP5jExg9UH"},"source":["A partir de ahora, usted deberá trabajar con código Pytorch para resolver las actividades que le pedimos. "]},{"cell_type":"markdown","metadata":{"id":"jRGgEuquhVQu"},"source":["### Actividad 1\n","\n","Al igual que en TP anterior, trabajaremos con el dataset `fifa2021_training.csv`. En al siguiente celda, usted deberá escribir el código necesario para:\n","\n","1. Cargar el dataset.\n","2. Eliminar todas las columnas excepto: Height, Weight, Age, Sex, Position y todas las features de habilidades.\n","3. Transformar las variable Sex a codificación one-hot\n","4. Separar el dataframe en dos: uno llamado X que contenga todas las features y otro llamado Y que contenga la columna Position (etiqueta)\n","5. Separar ambos dataframes en entrenamiento (70%) y prueba (30%)\n","6. Convertir los 4 dataframes generados en tensores Pytorch"]},{"cell_type":"code","metadata":{"id":"-0VuQSzeFozi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619317617802,"user_tz":180,"elapsed":6611,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"7c608f4d-82b4-44b4-be26-9deae9affebb"},"source":["# 1. CARGA DEL DATASET\n","# 1.1. Obtención de datos\n","!gdown https://drive.google.com/uc?id=1asxGtRgNyelvRnwRAt7ONRSRvuy8t0zJ # Reemplazo \".../file/d/...\" por \".../uc?id=...\"\n","!gdown https://drive.google.com/uc?id=1n4jjZRCcUc5x9FDdu934FixU6x9_8Rrt # Reemplazo \".../file/d/...\" por \".../uc?id=...\"\n","# 1.2. Carga del dataset\n","import pandas as pd\n","import numpy as np\n","\n","train_test_data = pd.read_csv('https://drive.google.com/uc?id=1asxGtRgNyelvRnwRAt7ONRSRvuy8t0zJ') # ver si se separa en train and test\n","infer_data = pd.read_csv('https://drive.google.com/uc?id=1n4jjZRCcUc5x9FDdu934FixU6x9_8Rrt')"],"execution_count":91,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1asxGtRgNyelvRnwRAt7ONRSRvuy8t0zJ\n","To: /content/fifa2021_training.csv\n","3.28MB [00:00, 52.0MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1n4jjZRCcUc5x9FDdu934FixU6x9_8Rrt\n","To: /content/fifa2021_test.csv\n","100% 1.37M/1.37M [00:00<00:00, 21.6MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TNG_MVwA8Ky","executionInfo":{"status":"ok","timestamp":1619317618996,"user_tz":180,"elapsed":542,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"7581dfb4-8c06-4632-ccd3-60f465e7a449"},"source":["# 2. ELIMINACIÓN DE COLUMNAS\n","variables_descartar = [\n","    'Position', # variable objetivo\n","    'ID',\n","    'Name',\n","    'Natinality',\n","    'BirthDate',\n","    'PlayerWorkRate',\n","    'Value',\n","    'Wage',\n","    'Club',\n","    'Club_KitNumber',\n","    'Club_JoinedClub',\n","    'Club_ContractLength',\n","]\n","\n","df_train_test_data = train_test_data.drop(columns=variables_descartar)\n","df_train_test_data.iloc[0]"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Overal             64\n","Potential          73\n","Height            188\n","Weight             79\n","PreferredFoot       R\n","Age                22\n","WeakFoot            3\n","SkillMoves          2\n","BallControl        62\n","Dribbling          55\n","Marking            60\n","SlideTackle        57\n","StandTackle        60\n","Aggression         71\n","Reactions          58\n","Interceptions      60\n","Vision             61\n","Composure          63\n","Crossing           44\n","ShortPass          67\n","LongPass           64\n","Acceleration       54\n","Stamina            66\n","Strength           70\n","Balance            54\n","SprintSpeed        46\n","Agility            58\n","Jumping            57\n","Heading            53\n","ShotPower          55\n","Finishing          39\n","LongShots          43\n","Curve              39\n","FKAcc              33\n","Penalties          43\n","Volleys            41\n","GKDiving           13\n","GKHandling         10\n","GKKicking          13\n","GKReflexes         12\n","Sex              Male\n","Name: 0, dtype: object"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"code","metadata":{"id":"kXc7WiIdGArQ","executionInfo":{"status":"ok","timestamp":1619317622356,"user_tz":180,"elapsed":527,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["# 3. TRANSFORMACIONES\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import make_column_transformer\n","\n","variables_categoricas = df_train_test_data.select_dtypes(include=np.object).columns\n","variables_numericas   = df_train_test_data.select_dtypes(include=np.number).columns\n","\n","transformador = make_column_transformer(\n","    (OneHotEncoder(),  variables_categoricas), # PreferredFoot, Sex\n","    (StandardScaler(), variables_numericas),   # Overal, Potential, Height, etc.\n","    remainder='drop' # descarta las columnas no mencionadas en las transformaciones\n",")\n","#transformador"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"5vvPPwJ8JC8S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619307922666,"user_tz":180,"elapsed":510,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"447dc6bb-962a-4c80-a987-24fd7fa66c40"},"source":["# 5. SEPARACIÓN DEL DATAFRAME EN ENTRENAMIENTO Y PRUEBA\n","from sklearn.model_selection import train_test_split\n","\n","train_data, test_data = train_test_split(train_test_data, stratify=train_test_data.Position, test_size=0.3, random_state=42)\n","#X_train\n","\n","# Entrenamiento del transformador\n","transformador.fit(train_data)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n","                  transformer_weights=None,\n","                  transformers=[('onehotencoder',\n","                                 OneHotEncoder(categories='auto', drop=None,\n","                                               dtype=<class 'numpy.float64'>,\n","                                               handle_unknown='error',\n","                                               sparse=True),\n","                                 Index(['PreferredFoot', 'Sex'], dtype='object')),\n","                                ('standardscaler',\n","                                 StandardScaler(copy=True, with_mean=True,\n","                                                with_std=True)...\n","       'StandTackle', 'Aggression', 'Reactions', 'Interceptions', 'Vision',\n","       'Composure', 'Crossing', 'ShortPass', 'LongPass', 'Acceleration',\n","       'Stamina', 'Strength', 'Balance', 'SprintSpeed', 'Agility', 'Jumping',\n","       'Heading', 'ShotPower', 'Finishing', 'LongShots', 'Curve', 'FKAcc',\n","       'Penalties', 'Volleys', 'GKDiving', 'GKHandling', 'GKKicking',\n","       'GKReflexes'],\n","      dtype='object'))],\n","                  verbose=False)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"CG4rH1tpjzuw","executionInfo":{"status":"ok","timestamp":1619318031827,"user_tz":180,"elapsed":562,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["# 4. SEPARACIÓN DEL DATAFRAME EN FEATURES Y LABEL (A PROPÓSITO EL ORDEN 4 DESPUÉS DEL 5. PARECE IMPORTANTE AL SEPARAR EL DATAFRAME USAR LA VARIABLE \n","#    \"stratify\", ya que garantiza la misma propoción de labels en el conjunto de entrenamiento)\n","\n","# Entrenar transformador\n","transformador.fit(train_data)\n","\n","# Transformación datasets\n","infer_data['Position'] = None\n","X_train = transformador.transform(train_data)\n","X_test = transformador.transform(test_data)\n","X_infer = transformador.transform(infer_data)\n","\n","# Transformación de variable objetivo\n","from sklearn.preprocessing import LabelEncoder\n","\n","transformador_etiquetas = LabelEncoder()\n","transformador_etiquetas.fit(train_data.Position)\n","\n","Y_train = transformador_etiquetas.transform(train_data.Position)\n","Y_test = transformador_etiquetas.transform(test_data.Position)"],"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kazIDwjWjT8S"},"source":["### Actividad 2\n","\n","Implementar 3 MLP con dos capas oculta y una capa de salida que permita clasificar a los jugadores entre las cuatro posiciones disponibles. Estos modelos deberán llamarse:\n","\n","1. `modelo_chico`: tiene 4 neuronas en cada capa oculta.\n","2. `modelo_medio`: tiene 16 neuronas en cada capa oculta.\n","3. `modelo_grande`: tiene 256 neuronas en cada capa oculta."]},{"cell_type":"code","metadata":{"id":"ikIRjny8Kb8d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618950231182,"user_tz":180,"elapsed":6750,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"8f3e1df1-ee82-4f02-fad5-8eee8256bbec"},"source":["# DESCOMENTAR. ESTE BLOQUE ANDA OK\n","# # Instanciar Dataset de Pytorch\n","# import torch\n","# from torch.utils.data import Dataset\n","\n","# class Tabular(Dataset):\n","#     def __init__(self, X, Y=None):\n","#         self.X = X.astype(np.float32) # soluciona \"Expected object of scalar type Float but got scalar type Double\"\n","#         self.Y = Y \n","\n","#     def __len__(self):\n","#         return len(self.X)\n","    \n","#     def __getitem__(self, item):\n","#         if self.Y is None:\n","#             return self.X[item]\n","#         else:\n","#             return self.X[item], self.Y[item]\n","        \n","# ds_train = Tabular(X_train, Y_train)\n","\n","# # Instanciar Dataloaders de Pytorch\n","# from torch.utils.data import DataLoader\n","\n","# dl_train = DataLoader(ds_train, batch_size=32, shuffle=True)\n","\n","# X_test = torch.as_tensor(X_test).float() # En lugar de \"torch.tensor...\" uso \"torch.as_tensor...\" o \"X_test.clone().detach().requires_grad_(True)\" sino me salue un warning ¿?\n","# X_infer = torch.as_tensor(X_infer).float() # En lugar de \"torch.tensor...\" uso \"torch.as_tensor...\" o \"X_infer.clone().detach().requires_grad_(True)\" sino me salue un warning ¿?\n","# Y_test = torch.as_tensor(Y_test) # En lugar de \"torch.tensor...\" uso \"torch.as_tensor...\" o \"Y_test.clone().detach()\" sino me salue un warning ¿?\n","\n","# # Instanciar Modelo\n","# import torch.nn as nn\n","\n","# IN  = X_train.shape[1]\n","# OUT = len(transformador_etiquetas.classes_)\n","\n","# modelo = nn.Sequential(\n","#     nn.Linear(IN,  8),\n","#     nn.Linear(8, 64), nn.ReLU(),\n","#     nn.Linear(64, 32), nn.ReLU(),\n","#     nn.Linear(32, OUT)\n","# )\n","\n","# # Definición del criterio y el optimizador\n","# from collections import Counter\n","\n","# cantidades = Counter(train_data.Position.values)\n","# # print(transformador_etiquetas.classes_) # ORDEN ETIQUETAS: 'DEF' 'FWD' 'GK' 'MID'\n","\n","# # Tensor de pesos\n","# pesos = torch.tensor([cantidades['DEF'], cantidades['FWD'], cantidades['GK'],\n","#                       cantidades['MID']], dtype=torch.float32)\n","# pesos = pesos / pesos.sum()\n","\n","# #criterio = nn.CrossEntropyLoss()\n","# criterio = nn.CrossEntropyLoss(weight=pesos)\n","# optimizador = torch.optim.Adam(modelo.parameters(), lr=0.0001)\n","\n","# # Entrenamiento del modelo\n","# from sklearn.metrics import balanced_accuracy_score\n","\n","# epocas = 20\n","\n","# for epoca in range(epocas):\n","#     # activa capas Dropout, BatchNorm si las hubiese\n","#     modelo.train()\n","\n","#     perdidas_train = []\n","    \n","#     for X_lote, Y_lote in dl_train:\n","#         optimizador.zero_grad()\n","\n","#         predicciones = modelo(X_lote)\n","#         perdida = criterio(predicciones, Y_lote)\n","\n","#         perdida.backward()\n","#         optimizador.step()\n","        \n","#         perdidas_train.append(perdida.item())\n","    \n","#     # desactiva capas Dropout, BatchNorm si las hubiese\n","#     modelo.eval()\n","    \n","#     with torch.no_grad():\n","#         predicciones = modelo(X_test)\n","#         perdida = criterio(predicciones, Y_test)\n","        \n","#         Y_pred = predicciones.argmax(dim=1) # selecciona la clase con mayor probabilidad\n","        \n","#         efectividad = balanced_accuracy_score(Y_test, Y_pred)\n","    \n","    \n","#     print(f'{epoca:3d}  |  Train loss: {np.mean(perdidas_train):.3f}    Valid loss: {perdida:.3f}    Valid accuracy: {efectividad:.2f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0  |  Train loss: 1.306    Valid loss: 1.049    Valid accuracy: 0.70\n","  1  |  Train loss: 0.731    Valid loss: 0.543    Valid accuracy: 0.79\n","  2  |  Train loss: 0.457    Valid loss: 0.422    Valid accuracy: 0.83\n","  3  |  Train loss: 0.380    Valid loss: 0.372    Valid accuracy: 0.85\n","  4  |  Train loss: 0.342    Valid loss: 0.343    Valid accuracy: 0.86\n","  5  |  Train loss: 0.319    Valid loss: 0.325    Valid accuracy: 0.86\n","  6  |  Train loss: 0.304    Valid loss: 0.313    Valid accuracy: 0.87\n","  7  |  Train loss: 0.294    Valid loss: 0.303    Valid accuracy: 0.87\n","  8  |  Train loss: 0.286    Valid loss: 0.296    Valid accuracy: 0.87\n","  9  |  Train loss: 0.280    Valid loss: 0.291    Valid accuracy: 0.87\n"," 10  |  Train loss: 0.274    Valid loss: 0.287    Valid accuracy: 0.87\n"," 11  |  Train loss: 0.271    Valid loss: 0.285    Valid accuracy: 0.87\n"," 12  |  Train loss: 0.268    Valid loss: 0.282    Valid accuracy: 0.87\n"," 13  |  Train loss: 0.265    Valid loss: 0.279    Valid accuracy: 0.87\n"," 14  |  Train loss: 0.262    Valid loss: 0.278    Valid accuracy: 0.87\n"," 15  |  Train loss: 0.261    Valid loss: 0.275    Valid accuracy: 0.87\n"," 16  |  Train loss: 0.259    Valid loss: 0.274    Valid accuracy: 0.88\n"," 17  |  Train loss: 0.257    Valid loss: 0.272    Valid accuracy: 0.88\n"," 18  |  Train loss: 0.256    Valid loss: 0.271    Valid accuracy: 0.87\n"," 19  |  Train loss: 0.255    Valid loss: 0.269    Valid accuracy: 0.88\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v_Z7NDAt-KBJ","executionInfo":{"status":"ok","timestamp":1619318037917,"user_tz":180,"elapsed":574,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["import torch.nn as nn\n","\n","IN  = X_train.shape[1]\n","OUT = len(transformador_etiquetas.classes_)\n","\n","modelo_chico = nn.Sequential(\n","    nn.Linear(IN,  4),\n","    nn.Linear(4, 4), nn.ReLU(),\n","    nn.Linear(4, 4), nn.ReLU(),\n","    nn.Linear(4, OUT)\n",")\n","\n","modelo_medio = nn.Sequential(\n","    nn.Linear(IN,  16),\n","    nn.Linear(16, 16), nn.ReLU(),\n","    nn.Linear(16, 16), nn.ReLU(),\n","    nn.Linear(16, OUT)\n",")\n","\n","modelo_grande = nn.Sequential(\n","    nn.Linear(IN,  256),\n","    nn.Linear(256, 256), nn.ReLU(),\n","    nn.Linear(256, 256), nn.ReLU(),\n","    nn.Linear(256, OUT)\n",")\n"],"execution_count":106,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AI_W_fQKkdcN"},"source":["### Actividad 3\n","\n","Leer detalladamente el código provisto para cada una de las siguientes funciones y entender su comportamiento. En la siguiente actividad deberá utilizarlas así que preste atención a todos los detalles. \n","\n","Funciones:\n","\n","* `load_array`: devuelve un iterador para obtener los batchs de un dataset\n","  * `data_arrays`: tensor o tupla de tensores que contiene el dataset\n","  * `batch_size`: tamaño de batch\n","* `evaluate_loss`: devuelve la función de pérdida calculada para un batch\n","  * `net`: modelo\n","  * `data_iter`: iterador sobre el batch\n","  * `loss`: función de pérdida a calcular\n","* `accuracy`: devuelve la cantidad de elementos que se predijeron correctamente\n","  * `y_hat`: predicciones\n","  * `y`: etiquetas\n","* `train_epoch_ch3`: entrena una epoch y devuelve la función de pérdida y el accuracy sobre el dataset completo\n","  * `net`: modelo\n","  * `train_iter`: iterador sobre el datset de entrenamiento completo\n","  * `loss`: función de pérdida\n","  * `updater`: algoritmo de optimización\n","\n","Clases:\n","\n","* `Accumulator`: objeto que almacena sumas sobre varias variables"]},{"cell_type":"code","metadata":{"id":"ETh2fZJ6M4kl","executionInfo":{"status":"ok","timestamp":1619318847088,"user_tz":180,"elapsed":559,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["# def load_array(data_arrays, batch_size, is_train=True):\n","  # \"\"\"Construct a PyTorch data iterator.\"\"\"\n","  # dataset = data.TensorDataset(*data_arrays)\n","  # return data.DataLoader(dataset, batch_size, shuffle=is_train)\n","\n","def load_array(*data_arrays, batch_size, shuffle):\n","  \"\"\"Construct a PyTorch data iterator.\"\"\"  \n","  from torch.utils.data import DataLoader\n","  return DataLoader(*data_arrays, batch_size, shuffle)"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ka42OFilSFQt","executionInfo":{"status":"ok","timestamp":1619318043229,"user_tz":180,"elapsed":620,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["class Accumulator:  #save\n","    \"\"\"For accumulating sums over `n` variables.\"\"\"\n","    def __init__(self, n):\n","        self.data = [0.0] * n\n","\n","    def add(self, *args):\n","        self.data = [a + float(b) for a, b in zip(self.data, args)]\n","\n","    def reset(self):\n","        self.data = [0.0] * len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yDSxKLPR4oK","executionInfo":{"status":"ok","timestamp":1619318045218,"user_tz":180,"elapsed":759,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["def evaluate_loss(net, data_iter, loss):  #save\n","    \"\"\"Evaluate the loss of a model on the given dataset.\"\"\"\n","    metric = Accumulator(2)  # Sum of losses, no. of examples\n","    for X, y in data_iter:\n","        out = net(X)\n","        y = torch.max(y, 1)[1]\n","        l = loss(out, y)\n","        metric.add(l.sum(), l.numel())\n","    return metric[0] / metric[1]"],"execution_count":109,"outputs":[]},{"cell_type":"code","metadata":{"id":"uI4O8zKFPX1p","executionInfo":{"status":"ok","timestamp":1619317769099,"user_tz":180,"elapsed":534,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["# batch_size = 32\n","\n","# from torch.utils import data # Da error si no importo esto\n","\n","# data_iter_train = load_array((X_train,Y_train), batch_size)\n","# data_iter_test = load_array((X_test,Y_test), batch_size)"],"execution_count":100,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1pfzHPQVE4U","executionInfo":{"status":"ok","timestamp":1619318050650,"user_tz":180,"elapsed":548,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}}},"source":["def accuracy(y_hat, y):  #save\n","    \"\"\"Compute the number of correct predictions.\"\"\"\n","    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n","        y_hat = y_hat.argmax(axis=1)\n","    cmp = y_hat.type(y.dtype) == y\n","    return float(cmp.type(y.dtype).sum())\n","\n","def train_epoch_ch3(net, train_iter, loss, updater):  #save\n","    \"\"\"The training loop defined in Chapter 3.\"\"\"\n","    # Set the model to training mode\n","    if isinstance(net, torch.nn.Module):\n","        net.train()\n","    # Sum of training loss, sum of training accuracy, no. of examples\n","    metric = Accumulator(3)\n","    for X, y in train_iter:\n","        # Compute gradients and update parameters\n","        y_hat = net(X)\n","        y = torch.max(y, 1)[1]\n","        l = loss(y_hat, y)\n","        if isinstance(updater, torch.optim.Optimizer):\n","            # Using PyTorch in-built optimizer & loss criterion\n","            updater.zero_grad()\n","            l.backward()\n","            updater.step()\n","            metric.add(float(l) * len(y), accuracy(y_hat, y), y.numel())\n","        else:\n","            # Using custom built optimizer & loss criterion\n","            l.sum().backward()\n","            updater(X.shape[0])\n","            metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n","    # Return training loss and training accuracy\n","    return metric[0] / metric[2], metric[1] / metric[2]\n","\n"],"execution_count":110,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NzASpZI7pRpC"},"source":["### Actividad 4\n","\n","Implementar la función `train()` que reciba los siguientes parámetros:\n","\n","* `net`: modelo a entrenar\n","* `train_iter`: iterador sobre el dataset de entrenamiento completo\n","* `test_iter`: iterador sobre el dataset de prueba completo\n","* `writer`: instancia de `SummaryWriter` encargada de crear los registros para TensorBoard\n","* `name`: string que contiene el nombre del modelo a entrenar para mostrar en TensorBoard\n","* `num_epochs`: cantidad de épocas de entrenamiento\n","\n","Esta función debe llevar adelante las siguientes tareas:\n","\n","* entrenar el modelo 500 épocas\n","* registrar con el SummaryWriter para cada época:\n","  * valor de la función de pérdida sobre el conjunto de entrenamiento\n","  * valor de la función de pérdida sobre el conjunto de prueba\n","  * accuracy sobre el conjunto de entrenamiento\n","  * accuracy sobre el conjunto de prueba\n","* mostrar por pantalla el número de época para verificar el avance del entrenamiento\n","\n","**Tip**: se recomienda usar la función `add_scalars()` del `SummaryWriter` para asegurarse que las dos pérdidas y los dos accuracy se muestren en gráficos diferentes.\n","\n","**Aclaraciones**:\n","* La función de pérdida a utilizar debe ser **la entropía cruzada**\n","* El algoritmo de optimización a utilizar debe ser **Adam** con todos sus parámetros por defecto"]},{"cell_type":"code","metadata":{"id":"pVxcPglySSRT"},"source":["# def train(net, train_iter, test_iter, writer,name, num_epochs=500):\n","#     #Inserte su código aquí"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-GQCNEqqh7q","executionInfo":{"status":"ok","timestamp":1619318859465,"user_tz":180,"elapsed":6194,"user":{"displayName":"Exequiel Santucho","photoUrl":"","userId":"10709628178102361168"}},"outputId":"0bf98472-9acc-446c-9f75-78bfc1a0bf27"},"source":["net = modelo_chico\n","train_iter = [X_train, Y_train]\n","test_iter = [X_test, Y_test]\n","num_epochs = 20\n","\n","# def train(net, train_iter, test_iter, writer, name, num_epochs):\n","def train(net, train_iter, test_iter, num_epochs):\n","  # Instanciar Dataset de Pytorch\n","  import torch\n","  from torch.utils.data import Dataset\n","\n","  class Tabular(Dataset):\n","      def __init__(self, X, Y=None):\n","          self.X = X.astype(np.float32) # soluciona \"Expected object of scalar type Float but got scalar type Double\"\n","          self.Y = Y \n","\n","      def __len__(self):\n","          return len(self.X)\n","      \n","      def __getitem__(self, item):\n","          if self.Y is None:\n","              return self.X[item]\n","          else:\n","              return self.X[item], self.Y[item]\n","\n","  X_train = train_iter[0]\n","  Y_train = train_iter[1]\n","  ds_train = Tabular(X_train, Y_train)\n","\n","  # Instanciar Dataloaders de Pytorch # Lo hago con función load_array\n","  # from torch.utils.data import DataLoader\n","  # dl_train = DataLoader(ds_train, batch_size=32, shuffle=True)\n","  dl_train = load_array(ds_train, batch_size=32, shuffle=True)\n","\n","  X_test = test_iter[0]\n","  X_test = torch.as_tensor(X_test).float() # En lugar de \"torch.tensor...\" uso \"torch.as_tensor...\" o \"X_test.clone().detach().requires_grad_(True)\" sino me salue un warning ¿?\n","  \n","  Y_test = test_iter[1]\n","  Y_test = torch.as_tensor(Y_test) # En lugar de \"torch.tensor...\" uso \"torch.as_tensor...\" o \"Y_test.clone().detach()\" sino me salue un warning ¿?\n","  \n","  # Instanciar Modelo\n","  import torch.nn as nn\n","\n","  IN  = X_train.shape[1]\n","  OUT = len(transformador_etiquetas.classes_)\n","\n","  # modelo = nn.Sequential(\n","  #     nn.Linear(IN,  8),\n","  #     nn.Linear(8, 64), nn.ReLU(),\n","  #     nn.Linear(64, 32), nn.ReLU(),\n","  #     nn.Linear(32, OUT)\n","  # )\n","\n","  modelo = net\n","\n","  # Definición del criterio y el optimizador\n","  from collections import Counter\n","\n","  cantidades = Counter(train_data.Position.values)\n","  # print(transformador_etiquetas.classes_) # ORDEN ETIQUETAS: 'DEF' 'FWD' 'GK' 'MID'\n","\n","  # Tensor de pesos\n","  pesos = torch.tensor([cantidades['DEF'], cantidades['FWD'], cantidades['GK'],\n","                        cantidades['MID']], dtype=torch.float32)\n","  pesos = pesos / pesos.sum()\n","\n","  #criterio = nn.CrossEntropyLoss()\n","  criterio = nn.CrossEntropyLoss(weight=pesos)\n","  optimizador = torch.optim.Adam(modelo.parameters(), lr=0.0001)\n","\n","  # Entrenamiento del modelo\n","  from sklearn.metrics import balanced_accuracy_score\n","\n","  epocas = num_epochs\n","\n","  for epoca in range(epocas):\n","      # activa capas Dropout, BatchNorm si las hubiese\n","      modelo.train()\n","\n","      perdidas_train = []\n","      \n","      for X_lote, Y_lote in dl_train:\n","          optimizador.zero_grad()\n","\n","          predicciones = modelo(X_lote)\n","          perdida = criterio(predicciones, Y_lote)\n","\n","          perdida.backward()\n","          optimizador.step()\n","          \n","          perdidas_train.append(perdida.item())\n","      \n","      # desactiva capas Dropout, BatchNorm si las hubiese\n","      modelo.eval()\n","      \n","      with torch.no_grad():\n","          predicciones = modelo(X_test)\n","          perdida = criterio(predicciones, Y_test)\n","          \n","          Y_pred = predicciones.argmax(dim=1) # selecciona la clase con mayor probabilidad\n","          \n","          efectividad = balanced_accuracy_score(Y_test, Y_pred)\n","      \n","      \n","      print(f'{epoca:3d}  |  Train loss: {np.mean(perdidas_train):.3f}    Valid loss: {perdida:.3f}    Valid accuracy: {efectividad:.2f}')\n","\n","\n","train(net, train_iter, test_iter, num_epochs)\n","\n","# X_infer = torch.as_tensor(X_infer).float() # En lugar de \"torch.tensor...\" uso \"torch.as_tensor...\" o \"X_infer.clone().detach().requires_grad_(True)\" sino me salue un warning ¿?\n"],"execution_count":125,"outputs":[{"output_type":"stream","text":["  0  |  Train loss: 0.305    Valid loss: 0.314    Valid accuracy: 0.87\n","  1  |  Train loss: 0.304    Valid loss: 0.312    Valid accuracy: 0.87\n","  2  |  Train loss: 0.302    Valid loss: 0.310    Valid accuracy: 0.87\n","  3  |  Train loss: 0.300    Valid loss: 0.309    Valid accuracy: 0.87\n","  4  |  Train loss: 0.299    Valid loss: 0.308    Valid accuracy: 0.87\n","  5  |  Train loss: 0.297    Valid loss: 0.306    Valid accuracy: 0.87\n","  6  |  Train loss: 0.295    Valid loss: 0.305    Valid accuracy: 0.87\n","  7  |  Train loss: 0.294    Valid loss: 0.304    Valid accuracy: 0.88\n","  8  |  Train loss: 0.293    Valid loss: 0.303    Valid accuracy: 0.88\n","  9  |  Train loss: 0.291    Valid loss: 0.301    Valid accuracy: 0.88\n"," 10  |  Train loss: 0.291    Valid loss: 0.300    Valid accuracy: 0.88\n"," 11  |  Train loss: 0.290    Valid loss: 0.300    Valid accuracy: 0.88\n"," 12  |  Train loss: 0.288    Valid loss: 0.298    Valid accuracy: 0.88\n"," 13  |  Train loss: 0.287    Valid loss: 0.298    Valid accuracy: 0.88\n"," 14  |  Train loss: 0.286    Valid loss: 0.297    Valid accuracy: 0.88\n"," 15  |  Train loss: 0.285    Valid loss: 0.296    Valid accuracy: 0.88\n"," 16  |  Train loss: 0.285    Valid loss: 0.295    Valid accuracy: 0.88\n"," 17  |  Train loss: 0.284    Valid loss: 0.295    Valid accuracy: 0.88\n"," 18  |  Train loss: 0.283    Valid loss: 0.294    Valid accuracy: 0.88\n"," 19  |  Train loss: 0.283    Valid loss: 0.293    Valid accuracy: 0.88\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AhtwKDqysBw0"},"source":["### Actividad 5\n","\n","Utilizar la función train implementada en la actividad anterior para entrenar los 3 modelos generados en la Actividad 2. Luego utilizar TensorBoard para graficar su proceso de entrenamiento. En base a estas curvas responder si alguno de ellos está sufriendo overfitting o underfitting.\n","\n","**Aclaraciones**: \n","* El batch_size debe ser de 32."]},{"cell_type":"code","metadata":{"id":"MZWsQQtXV-eA"},"source":["#Inserte su código aquí"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NemYlPxuwQv"},"source":["### Actividad 6 (Opcional)\n","Utilizar la función anterior para entrenar 10 modelos nuevos. Estos modelos deben tener 2 capas ocultas y una capa de salida como los de la Actividad 2. LA diferencia es que vamos a variar la cantidad de neuronas por capa entre las potencias desde $2^{0}$  hasta $2^{10}$. \n","\n","Para cada uno de esos modelos finales, almacenar en `train_loss` el valor de la función de pérdida sobre el conjunto de entrenamiento y en `test_loss`,el valor sobre el conjunto de prueba.\n","\n","Por último, utilizar la función provista para graficar los datos y comparar con el gráfico de Sesgo vs Varianza visto en clase. ¿Cuál sería el tamaño óptimo entre los relevados?"]},{"cell_type":"code","metadata":{"id":"OLOUyh6-RlA3"},"source":["train_loss = []\n","test_loss = []\n","neurons = []\n","\n","#Inserte su código aquí\n","\n","df = pd.DataFrame(list(zip(neurons, train_loss,test_loss)),\n","               columns =['Neuronas_por_capa', 'Error_Entrenamiento', 'Error_Prueba'])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"abAs1eNusAQ1"},"source":["def plot(df):\n","  # multiple line plots\n","  K = range(0,12,2)\n","  neurons = [2**k for k in K]\n","  plt.plot( 'Neuronas_por_capa', 'Error_Entrenamiento', data=df, marker='', color='skyblue', linewidth=2)\n","  plt.plot( 'Neuronas_por_capa', 'Error_Prueba', data=df, marker='', color='olive', linewidth=2)\n","  # show legend\n","  plt.legend()\n","  plt.xscale('log')\n","  plt.xticks(neurons,[str(x)for x in neurons])\n","  # show graph\n","  plt.show()"],"execution_count":null,"outputs":[]}]}